{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khgxF-lhI1wR"
      },
      "source": [
        "# Start coding and Enjoy the journey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJymrJ-oI8IB"
      },
      "source": [
        "## Install the repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Details on modified/added files with respect to the original repo can be found in Visual-Place-Recognition-Project\\modifiedFiles.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFsrTTq9I1Gf",
        "outputId": "ca7e37a8-9ddb-43f3-bea4-8d90fac24865"
      },
      "outputs": [],
      "source": [
        "!git clone --recursive https://github.com/AML-Project-2025-2026/Visual-Place-Recognition-Project.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53HRC-nSJE7C"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2CfbJQHJj6Y",
        "outputId": "32417dab-45af-4653-a6fa-6e4cb3c208a2"
      },
      "outputs": [],
      "source": [
        "%cd Visual-Place-Recognition-Project/image-matching-models\n",
        "!pip install -e .[all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V535d4aSKcnf",
        "outputId": "52dea552-914c-40be-da11-b4b5aac69bdc"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rse_4XALGmt"
      },
      "source": [
        "## Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vTCvjA1LIR_",
        "outputId": "891506a2-df38-42b1-bfa2-251534f1303c"
      },
      "outputs": [],
      "source": [
        "!python download_datasets.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBWxIb-TLREy"
      },
      "source": [
        "## Run your First VPR Evalutation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2aF2j4CLnW1",
        "outputId": "82641b3e-b137-4e13-f3c1-c621fe142ec3"
      },
      "outputs": [],
      "source": [
        "!python VPR-methods-evaluation/main.py \\\n",
        "--num_workers 8 \\\n",
        "--batch_size 32 \\\n",
        "--log_dir log_dir \\\n",
        "--method=mixvpr --backbone=ResNet50 --descriptors_dimension=4096 \\\n",
        "--image_size 512 512 \\\n",
        "--database_folder 'data/sf_xs/val/database' \\\n",
        "--queries_folder 'data/sf_xs/val/queries' \\\n",
        "--num_preds_to_save 20 \\\n",
        "--recall_values 1 5 10 20 \\\n",
        "--save_for_uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh9OI9J6UpI9"
      },
      "source": [
        "## Run Image Matching on Retrieval Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyqOE1gXUsig",
        "outputId": "8bb1197e-ec1b-44d9-82fe-327785247364"
      },
      "outputs": [],
      "source": [
        "!python match_queries_preds.py \\\n",
        "--preds-dir 'logs/log_dir/2025-12-21_09-01-13/preds' \\\n",
        "--out-dir 'logs/log_dir/2025-12-21_09-01-13/inliers_loftr' \\\n",
        "--matcher 'loftr' \\\n",
        "--device 'cuda' \\\n",
        "--num-preds 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this cell to obtain the average processing time per query (not including pure reranking)\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "#Change here the path of the folder\n",
        "folder = Path(\"logs/log_dir/2025-12-29_15-05-42/inliers_loftr\")\n",
        "files = sorted(folder.glob(\"*.torch\"))\n",
        "\n",
        "if not files:\n",
        "    raise ValueError(f\"Nessun file .torch trovato in {folder}\")\n",
        "\n",
        "all_query_times = []\n",
        "\n",
        "for f in files:\n",
        "    try:\n",
        "        # weights_only=False to load \"timing\" dictionaries\n",
        "        data = torch.load(f, weights_only=False, map_location='cpu')\n",
        "        \n",
        "        if \"timing\" in data and \"total_query_time\" in data[\"timing\"]:\n",
        "            all_query_times.append(data[\"timing\"][\"total_query_time\"])\n",
        "        else:\n",
        "            print(f\"{f.name} non contiene info sul timing.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nel caricamento di {f.name}: {e}\")\n",
        "\n",
        "if all_query_times:\n",
        "    avg_query_time = np.mean(all_query_times)\n",
        "    std_query_time = np.std(all_query_times)\n",
        "    print(f\"Risultati su {len(all_query_times)} query\")\n",
        "    print(f\"Tempo medio per query: {avg_query_time:.4f} s\")\n",
        "    print(f\"Deviazione standard: {std_query_time:.4f} s\")\n",
        "    print(f\"Tempo medio stimato per singolo match: {avg_query_time/20:.4f} s\")\n",
        "else:\n",
        "    print(\"Nessun dato di timing valido estratto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px9GrJh9bKAZ"
      },
      "source": [
        "## Check Re-ranking Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZdV0x5xbRFM",
        "outputId": "11ed518a-1540-4363-f109-b4511ead3a9a"
      },
      "outputs": [],
      "source": [
        "!python reranking.py \\\n",
        "--preds-dir 'logs/log_dir/2025-12-29_15-05-42/preds' \\\n",
        "--inliers-dir 'logs/log_dir/2025-12-29_15-05-42/inliers_loftr' \\\n",
        "--num-preds 20 \\\n",
        "--recall-values 1 5 10 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this cell to draw the plots for the correlation between correctness and number of inliers (Top-1 retrieval)\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "from util import get_list_distances_from_preds\n",
        "\n",
        "#Change here the paths of the folders\n",
        "preds_folder = 'logs/log_dir/2025-12-28_13-41-54/preds'\n",
        "inliers_folder = Path('logs/log_dir/2025-12-28_13-41-54/inliers_loftr')\n",
        "threshold = 25\n",
        "\n",
        "inliers_correct = []\n",
        "inliers_wrong = []\n",
        "\n",
        "txt_files = glob(os.path.join(preds_folder, \"*.txt\"))\n",
        "txt_files.sort(key=lambda x: int(Path(x).stem))\n",
        "\n",
        "print(f\"Analizzando {len(txt_files)} query\")\n",
        "\n",
        "for txt_file_query in tqdm(txt_files):\n",
        "    #get_list_distances_from_preds returns the distances in txt file order\n",
        "    distances = get_list_distances_from_preds(txt_file_query)\n",
        "    dist_top1 = distances[0] # Because interested only in the first one\n",
        "    \n",
        "    #Retrieve the inliers of the first prediction\n",
        "    torch_file_query = inliers_folder.joinpath(Path(txt_file_query).name.replace('txt', 'torch'))\n",
        "    query_data = torch.load(torch_file_query, weights_only=False)\n",
        "    #results[0] matches the first line of the txt file\n",
        "    inliers_top1 = query_data['results'][0]['num_inliers'] \n",
        "    \n",
        "    if dist_top1 <= threshold:\n",
        "        inliers_correct.append(inliers_top1)\n",
        "    else:\n",
        "        inliers_wrong.append(inliers_top1)\n",
        "\n",
        "#plot \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.hist(inliers_wrong, bins=25, alpha=0.6, label='Wrong queries (dist > 25m)', color='red', density=True)\n",
        "\n",
        "plt.hist(inliers_correct, bins=25, alpha=0.6, label='Correct queries (dist <= 25m)', color='green', density=True)\n",
        "\n",
        "plt.title(\"Correlation between correctness and number of inliers (Top-1 retrieval)\")\n",
        "plt.xlabel(\"Number of inliers\")\n",
        "plt.ylabel(\"Density of  queries\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this to obtain the best threshold for adaptive reranking (smallest threshold that keeps 99% of performance). Note that --avg-full-rerank-time is passed as an argument to be changed\n",
        "!python adaptive_reranking.py --preds-dir 'logs/log_dir/2025-12-28_13-41-54/preds' inliers-dir 'logs/log_dir/2025-12-28_13-41-54/inliers_loftr' --taus 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 --num-preds 20 --avg-full-rerank-time 3.2708\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this to evaluate the performance and savings for adaptive reranking with a specific threshold. Note that --avg-full-rerank-time is passed as an argument to be changed\n",
        "!python adaptive_reranking_eval.py --preds-dir 'logs/log_dir/2025-12-28_13-41-54/preds' --inliers-dir 'logs/log_dir/2025-12-28_13-41-54/inliers_loftr' --tau 20 --avg-full-rerank-time 3.2708"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb7b898qlwbV"
      },
      "source": [
        "## Perform Uncertainty Evalutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHeq_U8tlynM",
        "outputId": "7ce4aeb1-db47-447f-b41e-4dfe2fb9de28"
      },
      "outputs": [],
      "source": [
        "!python -m vpr_uncertainty.eval \\\n",
        "--preds-dir '<path-to-predictions-folder>' \\\n",
        "--inliers-dir '<path-to-inliers-folder>' \\\n",
        "--z-data-path '<path-to-z-data-file>'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (nome_ambiente)",
      "language": "python",
      "name": "nome_ambiente"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
